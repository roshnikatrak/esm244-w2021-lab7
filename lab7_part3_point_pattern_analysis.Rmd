---
title: 'ESM 244 Lab 7 Part 3: Spatial point pattern analysis'
author: "Roshni Katrak-Adefowora"
date: "2/12/2021"
output: html_document
---

See: - CRS & proj4 components breakdown: https://www.earthdatascience.org/courses/earth-analytics/spatial-data-r/reproject-vector-data/

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(sf)
library(spatstat)
library(maptools) 
library(sp)
library(raster)
library(tmap)
```

This is an example of point pattern analysis with a density plot, and the G- & L- function (distance methods) to compare our observed points with simulated complete spatial randomness.

```{r}
# Read in the tree vole data
voles <- read_sf(dsn = here("redtreevoledata"), 
                 layer = "ds033") %>% 
  dplyr::select(COUNTY) %>% # Only select the county attribute
  filter(COUNTY == "HUM") %>% # Only keep observations in Humboldt County
  st_transform(crs = 4326) # Update CRS

# Plot it (exploratory)
plot(voles)

# Get Humboldt County outline
humboldt <- read_sf(dsn = here("redtreevoledata"), 
                    layer = "california_county_shape_file") %>% 
  filter(NAME == "Humboldt") %>% # Isolate Humboldt County
  dplyr::select(NAME) # Only keep one attribute (name) to simplify

# Set CRS
st_crs(humboldt) <- 4326 # Set CRS to match 

# plot them together
ggplot() +
  geom_sf(data = humboldt, 
          color = "darkorchid", 
          fill = "darkorchid4", 
          size = 1) +
  geom_sf(data = voles, 
          color = "orange", 
          alpha = 0.7, 
          size = 2) +
  theme_minimal()
```

These need to be combined into spatial point pattern data (points + window combo), and for point pattern analysis this **requires a 2D projection** (in this case, UTM), which is why there's this `proj4string` line here to specify the project (yes, this looks like a lot, just copy and paste the projection information exactly). This looks quite a bit different from what we've done so far - it uses functions in `spatstat` to create point patterns that play nicely with other functions for data viz & point pattern analysis.

```{r}
voles_sp <- as(voles,"Spatial") # Convert to object 'Spatial'
proj4string(voles_sp) <- "+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0" # Add UTM projection so that it's 2D (otherwise point pattern analysis invalid)
voles_ppp <- as(voles_sp, "ppp") # Convert to spatial point pattern

humboldt_sp <- as(humboldt, "Spatial") # Convert to object 'Spatial'
proj4string(humboldt_sp) <- "+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0" # Add UTM projection
humboldt_win <- as(humboldt_sp, "owin") # Convert to spatial point pattern

# Combine as a point pattern object (points + window):
voles_full <- ppp(voles_ppp$x, voles_ppp$y, window = humboldt_win)

plot(voles_full) # Illegal point (outside window) shows up as the plus sign
```
## Make a kernel density plot:

### Density

Run to see vole "hotspots" by kernel density, then see what happens when you change sigma here!

```{r}
voles_density <- density(voles_full, sigma = 0.03)

plot(voles_density)
```

Pretty clear that there are "hotspots" where voles are observed - both in the originally plotted data and in the density plot. How can we compare this to complete spatial randomness? 

```{r}
# Can you start viewing this in tmap? Yes, rasterize it: 
wgs84 = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
vole_raster <- raster(voles_density, crs = wgs84)

# Then plot: 
tmap_mode("view") #interactive viewing

tm_shape(vole_raster) +
  tm_raster(midpoint = NA, 
            palette = "Reds", 
            legend.show = FALSE)
```


## Nearest neighbor (G-function)

In last week's lecture, we learned about distance methods to compare our point pattern to a scenario of complete spatial randomness. Here, we'll use both the G- and L-functions (L function is the K-function, standardized...interpretation is the same) to compare our observed point pattern to a simulated CSR scenario, to help us determine if it is *more clustered* or *more uniform* than CSR.

What is going on in this code? 

- `r`: a sequence of distances (in the spatial units of the data) over which we'll calculate the proportion of points with nearest neighbor within that range

- `gfunction`: This uses the `envelope()` function within which we run simulations for CSR, *and* calculate the G-function value at distances *r* for each simulation. So this will calculate the G-function for *our* actual data, and also for simulations of CSR if we had the same number of observations in the window but they were independent. The `nsim = 100` here means there will be 100 simulations of CSR. The `nrank = 2` means that the second highest and second lowest values from simulations are shown as the "hi" and "lo" value envelopes, with the "theo" being the "theoretical value of the summary function under CSR (Complete Spatial Randomness, a uniform Poisson point process) if the simulations were generated according to CSR." So we're really comparing our "observed" data to the "theoretical CSR" here, and those "hi" and "lo" envelope bounds give us an idea of spread for the simulations. 
 
```{r}
r <- seq(0,0.15, by = 0.005) # Make a sequence of distances over which you'll calculate G(r)

gfunction <- envelope(voles_full, fun = Gest, r = r, nsim = 100, nrank = 2) # Calculate the actual and theoretical G(r) values, using 100 simulations of CRS for the "theoretical" outcome

gfunction # << Check the output of gfunction, then...

# Gather this to plot series in ggplot:
gfunction_long <- gfunction %>% 
  as.data.frame() %>% 
  pivot_longer(cols = obs:hi, names_to = "model", values_to = "g_val")

# Then make a graph in ggplot:
ggplot(data = gfunction_long, aes(x = r, y = g_val, group = model)) +
  geom_line(aes(color = model))
```

This again confirms clustering - our data (model = obs) has a greater proportion of events with nearest neighbor at *smaller distances* compared to a theoretical CSR scenario (model = theo). But remember, the G-function only considers the single nearest neighbor. 

Let's similarly look at the L-function (standardized K-function) which considers densities of observations within some distance R (expanding circles around each point) for comparison. This is using very similar code, but now the function is `Lest` for "L estimate", which calculates the density of events within growing circles around *each point*. That is much more intensive than just the single nearest neighbor, so I run `nsim = 10` here instead (you can do 100 or more again, you'll just notice that creating the simulations takes longer).

```{r}
r2 <- seq(0, 0.5, by = 0.05)

lfunction <- envelope(voles_full, fun = Lest, r = r2, nsim = 10, rank = 2, global = TRUE)

# Gather this to plot series in ggplot:
lfunction_long <- lfunction %>% 
  as.data.frame() %>% 
  pivot_longer(cols = obs:hi, names_to = "model", values_to = "k_val")

ggplot(data = lfunction_long, aes(x = r, y = k_val, group = model)) +
  geom_line(aes(color = model))
```

We again see that at lower distances, our data overall has a higher density of nearest neighbors compared to a simulated CSR scenario. Again, evidence of clustering. 

## End Lab 7 Part 3